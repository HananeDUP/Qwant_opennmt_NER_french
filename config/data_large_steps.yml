data:
  eval_features_file: ./dataset/train_valid/wiki_valid_words_bitext.txt
  eval_labels_file: ./dataset/train_valid/wiki_valid_tags_bitext.txt
  source_1_vocabulary: ./dataset/train_valid/wiki-src-train-vocab.txt
  source_2_vocabulary: ./dataset/train_valid/wiki-src-train-tkt-vocab.txt
  target_vocabulary: ./dataset/train_valid/wiki-tgt-train-vocab.txt
  train_features_file: ./dataset/train_valid/wiki_train_words_bitext.txt
  train_labels_file: ./dataset/train_valid/wiki_train_tags_bitext.txt
eval:
  batch_size: 10
  export_on_best: loss
  external_evaluators: bleu
  steps: 20000
infer:
  batch_size: 10
  length_bucket_width: null
model_dir: run/
params:
  average_loss_in_time: false
  learning_rate: 0.015
  num_hypotheses: 1
  optimizer: SGD
  optimizer_params:
    momentum: 0.9
  clip_gradients: 5.0
  decay_type: NoamDecay
  decay_params:
    model_dim: 512
    warmup_steps: 4000
  decay_rate: 0.05
  decay_steps: 2000
  start_decay_steps: 1000
  scheduled_sampling_type: inverse_sigmoid
  minimum_learning_rate: 0.00001
 
score:
  batch_size: 10

train:
  batch_size: 32
  batch_type: examples
  max_step: 40000
  sample_buffer_size: -1
  save_checkpoints_steps: 20000
  save_summary_steps: 2000